{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\shash\\\\Desktop\\\\tamil_dict\\\\e-dict\\\\src\\\\speechinput.js\";\nimport React, { Component } from 'react';\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nimport { Fragment as _Fragment } from \"react/jsx-dev-runtime\";\nvar recognition = new window.webkitSpeechRecognition();\nvar final_transcript = '';\nvar interim_transcript = '';\n\nrecognition.onresult = function (event) {\n  var interim_transcript = '';\n\n  if (typeof event.results == 'undefined') {\n    recognition.onend = null;\n    recognition.stop();\n    return;\n  }\n\n  for (var i = event.resultIndex; i < event.results.length; ++i) {\n    if (event.results[i].isFinal) {\n      final_transcript += event.results[i][0].transcript;\n    } else {\n      interim_transcript += event.results[i][0].transcript;\n    }\n  }\n};\n\nclass Speechinput extends Component {\n  constructor(props) {\n    super(props);\n    this.state = {\n      speaking: null,\n      recognizing: null,\n      final_transcript: '',\n      recognition: null\n    };\n    this.startButton = this.startButton.bind(this); //this.setConfign = this.setConfign.bind(this);\n  }\n\n  async componentDidMount() {\n    this.setState({\n      'speaking': false\n    });\n    recognition.lang = 'ta-IN';\n    recognition.continuous = true;\n    recognition.interimResults = true;\n  }\n\n  startButton() {\n    const is_listening = this.state.speaking;\n\n    if (is_listening) {\n      recognition.stop();\n      return;\n    }\n\n    recognition.start();\n  }\n\n  render() {\n    return /*#__PURE__*/_jsxDEV(_Fragment, {\n      children: [this.state.speaking === true ? \"you are speaking...\" : \"Click button speak to speak\", /*#__PURE__*/_jsxDEV(\"button\", {\n        type: \"button\",\n        onClick: this.startButton,\n        children: [\" \", this.state.speaking === true ? \"Stop\" : \"Speak\", \" \"]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 58,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: [final_transcript, \" \", interim_transcript]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 59,\n        columnNumber: 17\n      }, this)]\n    }, void 0, true);\n  }\n\n}\n\nexport default Speechinput;","map":{"version":3,"sources":["C:/Users/shash/Desktop/tamil_dict/e-dict/src/speechinput.js"],"names":["React","Component","SpeechRecognition","useSpeechRecognition","recognition","window","webkitSpeechRecognition","final_transcript","interim_transcript","onresult","event","results","onend","stop","i","resultIndex","length","isFinal","transcript","Speechinput","constructor","props","state","speaking","recognizing","startButton","bind","componentDidMount","setState","lang","continuous","interimResults","is_listening","start","render"],"mappings":";AAAA,OAAOA,KAAP,IAAgBC,SAAhB,QAAiC,OAAjC;AACA,OAAOC,iBAAP,IAA4BC,oBAA5B,QAAwD,0BAAxD;;;AAEA,IAAIC,WAAW,GAAG,IAAIC,MAAM,CAACC,uBAAX,EAAlB;AACA,IAAIC,gBAAgB,GAAG,EAAvB;AACA,IAAIC,kBAAkB,GAAG,EAAzB;;AAEAJ,WAAW,CAACK,QAAZ,GAAuB,UAASC,KAAT,EAAgB;AACnC,MAAIF,kBAAkB,GAAG,EAAzB;;AACA,MAAI,OAAOE,KAAK,CAACC,OAAb,IAAyB,WAA7B,EAA0C;AACtCP,IAAAA,WAAW,CAACQ,KAAZ,GAAoB,IAApB;AACAR,IAAAA,WAAW,CAACS,IAAZ;AACA;AACH;;AACD,OAAK,IAAIC,CAAC,GAAGJ,KAAK,CAACK,WAAnB,EAAgCD,CAAC,GAAGJ,KAAK,CAACC,OAAN,CAAcK,MAAlD,EAA0D,EAAEF,CAA5D,EAA+D;AAC3D,QAAIJ,KAAK,CAACC,OAAN,CAAcG,CAAd,EAAiBG,OAArB,EAA8B;AAC9BV,MAAAA,gBAAgB,IAAIG,KAAK,CAACC,OAAN,CAAcG,CAAd,EAAiB,CAAjB,EAAoBI,UAAxC;AACC,KAFD,MAEO;AACPV,MAAAA,kBAAkB,IAAIE,KAAK,CAACC,OAAN,CAAcG,CAAd,EAAiB,CAAjB,EAAoBI,UAA1C;AACC;AACJ;AACJ,CAdD;;AAgBA,MAAMC,WAAN,SAA0BlB,SAA1B,CAAoC;AAChCmB,EAAAA,WAAW,CAACC,KAAD,EAAQ;AACf,UAAMA,KAAN;AACA,SAAKC,KAAL,GAAa;AACTC,MAAAA,QAAQ,EAAG,IADF;AAETC,MAAAA,WAAW,EAAE,IAFJ;AAGTjB,MAAAA,gBAAgB,EAAE,EAHT;AAITH,MAAAA,WAAW,EAAG;AAJL,KAAb;AAOA,SAAKqB,WAAL,GAAmB,KAAKA,WAAL,CAAiBC,IAAjB,CAAsB,IAAtB,CAAnB,CATe,CAUf;AACH;;AAEsB,QAAjBC,iBAAiB,GAAG;AACtB,SAAKC,QAAL,CAAc;AAAC,kBAAW;AAAZ,KAAd;AACAxB,IAAAA,WAAW,CAACyB,IAAZ,GAAiB,OAAjB;AACAzB,IAAAA,WAAW,CAAC0B,UAAZ,GAAwB,IAAxB;AACA1B,IAAAA,WAAW,CAAC2B,cAAZ,GAA2B,IAA3B;AACH;;AAEDN,EAAAA,WAAW,GAAG;AACV,UAAMO,YAAY,GAAG,KAAKV,KAAL,CAAWC,QAAhC;;AACA,QAAIS,YAAJ,EAAkB;AACd5B,MAAAA,WAAW,CAACS,IAAZ;AACA;AACH;;AACDT,IAAAA,WAAW,CAAC6B,KAAZ;AACH;;AAEDC,EAAAA,MAAM,GAAG;AACL,wBACI;AAAA,iBACK,KAAKZ,KAAL,CAAWC,QAAX,KAAyB,IAAzB,GAAgC,qBAAhC,GAAwD,6BAD7D,eAEI;AAAQ,QAAA,IAAI,EAAC,QAAb;AAAsB,QAAA,OAAO,EAAE,KAAKE,WAApC;AAAA,wBAAmD,KAAKH,KAAL,CAAWC,QAAX,KAAwB,IAAxB,GAA+B,MAA/B,GAAwC,OAA3F;AAAA;AAAA;AAAA;AAAA;AAAA,cAFJ,eAGI;AAAA,mBAAIhB,gBAAJ,OAAuBC,kBAAvB;AAAA;AAAA;AAAA;AAAA;AAAA,cAHJ;AAAA,oBADJ;AAOH;;AAtC+B;;AAwCpC,eAAeW,WAAf","sourcesContent":["import React, { Component } from 'react';\r\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\r\n\r\nvar recognition = new window.webkitSpeechRecognition();\r\nvar final_transcript = '';\r\nvar interim_transcript = ''; \r\n\r\nrecognition.onresult = function(event) {\r\n    var interim_transcript = '';\r\n    if (typeof(event.results) == 'undefined') {\r\n        recognition.onend = null;\r\n        recognition.stop();\r\n        return;\r\n    }\r\n    for (var i = event.resultIndex; i < event.results.length; ++i) {\r\n        if (event.results[i].isFinal) {\r\n        final_transcript += event.results[i][0].transcript;\r\n        } else {\r\n        interim_transcript += event.results[i][0].transcript;\r\n        }\r\n    }\r\n};\r\n\r\nclass Speechinput extends Component {\r\n    constructor(props) {\r\n        super(props);\r\n        this.state = {\r\n            speaking : null,\r\n            recognizing: null,\r\n            final_transcript: '',\r\n            recognition : null\r\n\r\n        }\r\n        this.startButton = this.startButton.bind(this);\r\n        //this.setConfign = this.setConfign.bind(this);\r\n    }\r\n\r\n    async componentDidMount() {\r\n        this.setState({'speaking':false});\r\n        recognition.lang='ta-IN';\r\n        recognition.continuous =true;\r\n        recognition.interimResults=true;\r\n    }\r\n\r\n    startButton() {\r\n        const is_listening = this.state.speaking;\r\n        if (is_listening) {\r\n            recognition.stop();\r\n            return;\r\n        }\r\n        recognition.start();\r\n    }\r\n\r\n    render() {\r\n        return(\r\n            <>\r\n                {this.state.speaking ===  true ? \"you are speaking...\" : \"Click button speak to speak\"}\r\n                <button type=\"button\" onClick={this.startButton}> {this.state.speaking === true ? \"Stop\" : \"Speak\"} </button>\r\n                <p>{final_transcript} {interim_transcript}</p>\r\n            </>\r\n        )\r\n    }\r\n}\r\nexport default Speechinput;"]},"metadata":{},"sourceType":"module"}