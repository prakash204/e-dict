{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\shash\\\\Desktop\\\\tamil_dict\\\\e-dict\\\\src\\\\speechinput.js\";\nimport React, { Component } from 'react';\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nimport { Fragment as _Fragment } from \"react/jsx-dev-runtime\";\n\nclass Speechinput extends Component {\n  constructor(props) {\n    super(props);\n    this.state = {\n      speaking: null,\n      recognizing: null,\n      final_transcript: '',\n      recognition: null\n    };\n    this.startButton = this.startButton.bind(this);\n    this.setConfig = this.setConfig.bind(this);\n  }\n\n  componentDidMount() {\n    this.setState({\n      'speaking': false,\n      'recognition': new window.webkitSpeechRecognition()\n    });\n  }\n\n  async setrecogconfig() {\n    this.setState({\n      'final_transcript': '',\n      'recognition.lang': 'ta-IN',\n      'recognition.continuous': true,\n      'recognition.interimResults': true\n    });\n    return \"\";\n  }\n\n  async startButton() {\n    const is_listening = this.state.speaking;\n\n    if (is_listening) {\n      this.state.recognition.stop();\n      return;\n    }\n\n    await setconfig();\n    this.state.recognition.start();\n  }\n\n  render() {\n    return /*#__PURE__*/_jsxDEV(_Fragment, {\n      children: [this.state.speaking === true ? \"you are speaking...\" : \"Click button speak to speak\", /*#__PURE__*/_jsxDEV(\"button\", {\n        type: \"button\",\n        onClick: this.startButton,\n        children: [\" \", this.state.speaking ? \"Stop\" : \"Speak\", \" \"]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 46,\n        columnNumber: 17\n      }, this)]\n    }, void 0, true);\n  }\n\n}\n\nexport default Speechinput;","map":{"version":3,"sources":["C:/Users/shash/Desktop/tamil_dict/e-dict/src/speechinput.js"],"names":["React","Component","SpeechRecognition","useSpeechRecognition","Speechinput","constructor","props","state","speaking","recognizing","final_transcript","recognition","startButton","bind","setConfig","componentDidMount","setState","window","webkitSpeechRecognition","setrecogconfig","is_listening","stop","setconfig","start","render"],"mappings":";AAAA,OAAOA,KAAP,IAAgBC,SAAhB,QAAiC,OAAjC;AACA,OAAOC,iBAAP,IAA4BC,oBAA5B,QAAwD,0BAAxD;;;;AAEA,MAAMC,WAAN,SAA0BH,SAA1B,CAAoC;AAChCI,EAAAA,WAAW,CAACC,KAAD,EAAQ;AACf,UAAMA,KAAN;AACA,SAAKC,KAAL,GAAa;AACTC,MAAAA,QAAQ,EAAG,IADF;AAETC,MAAAA,WAAW,EAAE,IAFJ;AAGTC,MAAAA,gBAAgB,EAAE,EAHT;AAITC,MAAAA,WAAW,EAAG;AAJL,KAAb;AAOA,SAAKC,WAAL,GAAmB,KAAKA,WAAL,CAAiBC,IAAjB,CAAsB,IAAtB,CAAnB;AACA,SAAKC,SAAL,GAAiB,KAAKA,SAAL,CAAeD,IAAf,CAAoB,IAApB,CAAjB;AACH;;AAEDE,EAAAA,iBAAiB,GAAG;AAChB,SAAKC,QAAL,CAAc;AAAC,kBAAW,KAAZ;AAAkB,qBAAc,IAAIC,MAAM,CAACC,uBAAX;AAAhC,KAAd;AACH;;AAEmB,QAAdC,cAAc,GAAG;AACnB,SAAKH,QAAL,CAAc;AACd,0BAAmB,EADL;AAEd,0BAAmB,OAFL;AAGd,gCAA0B,IAHZ;AAId,oCAA8B;AAJhB,KAAd;AAMA,WAAO,EAAP;AACH;;AAEgB,QAAXJ,WAAW,GAAG;AAChB,UAAMQ,YAAY,GAAG,KAAKb,KAAL,CAAWC,QAAhC;;AACA,QAAIY,YAAJ,EAAkB;AACd,WAAKb,KAAL,CAAWI,WAAX,CAAuBU,IAAvB;AACA;AACH;;AACD,UAAMC,SAAS,EAAf;AACA,SAAKf,KAAL,CAAWI,WAAX,CAAuBY,KAAvB;AACH;;AAEDC,EAAAA,MAAM,GAAG;AACL,wBACI;AAAA,iBACK,KAAKjB,KAAL,CAAWC,QAAX,KAAyB,IAAzB,GAAgC,qBAAhC,GAAwD,6BAD7D,eAEI;AAAQ,QAAA,IAAI,EAAC,QAAb;AAAsB,QAAA,OAAO,EAAE,KAAKI,WAApC;AAAA,wBAAmD,KAAKL,KAAL,CAAWC,QAAX,GAAsB,MAAtB,GAA+B,OAAlF;AAAA;AAAA;AAAA;AAAA;AAAA,cAFJ;AAAA,oBADJ;AAMH;;AA7C+B;;AA+CpC,eAAeJ,WAAf","sourcesContent":["import React, { Component } from 'react';\r\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\r\n\r\nclass Speechinput extends Component {\r\n    constructor(props) {\r\n        super(props);\r\n        this.state = {\r\n            speaking : null,\r\n            recognizing: null,\r\n            final_transcript: '',\r\n            recognition : null\r\n\r\n        }\r\n        this.startButton = this.startButton.bind(this);\r\n        this.setConfig = this.setConfig.bind(this);\r\n    }\r\n\r\n    componentDidMount() {\r\n        this.setState({'speaking':false,'recognition':new window.webkitSpeechRecognition()});\r\n    }\r\n\r\n    async setrecogconfig() {\r\n        this.setState({\r\n        'final_transcript':'',\r\n        'recognition.lang':'ta-IN',\r\n        'recognition.continuous' :true,\r\n        'recognition.interimResults' :true\r\n        });\r\n        return \"\";\r\n    }\r\n\r\n    async startButton() {\r\n        const is_listening = this.state.speaking;\r\n        if (is_listening) {\r\n            this.state.recognition.stop();\r\n            return;\r\n        }\r\n        await setconfig();\r\n        this.state.recognition.start();\r\n    }\r\n\r\n    render() {\r\n        return(\r\n            <>\r\n                {this.state.speaking ===  true ? \"you are speaking...\" : \"Click button speak to speak\"}\r\n                <button type=\"button\" onClick={this.startButton}> {this.state.speaking ? \"Stop\" : \"Speak\"} </button>\r\n            </>\r\n        )\r\n    }\r\n}\r\nexport default Speechinput;"]},"metadata":{},"sourceType":"module"}