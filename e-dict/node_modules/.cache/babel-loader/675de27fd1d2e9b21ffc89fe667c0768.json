{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\shash\\\\Desktop\\\\tamil_dict\\\\e-dict\\\\src\\\\speechinput.js\";\nimport React, { Component } from 'react';\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nimport { Fragment as _Fragment } from \"react/jsx-dev-runtime\";\n\nclass Speechinput extends Component {\n  constructor(props) {\n    super(props);\n    state = {\n      speaking: null,\n      recognizing: null,\n      final_transcript: '',\n      recognition: new webkitSpeechRecognition()\n    };\n  }\n\n  componentDidMount() {\n    this.setState({\n      'speaking': false\n    });\n  }\n\n  startButton() {\n    const is_listening = this.state.speaking;\n\n    if (is_listening) {\n      recognition.stop();\n      return;\n    }\n\n    this.setState({\n      'final_transcript': '',\n      'recognition.lang': 'ta-IN',\n      'recognition.continuous': true,\n      'recognition.interimResults': true\n    });\n    this.state.recognition.start();\n    ignore_onend = false;\n    final_span.innerHTML = '';\n    interim_span.innerHTML = '';\n    start_img.src = 'https://media1.giphy.com/media/LU0EPR6tWaNREI35hU/giphy.gif';\n    showInfo('info_allow');\n    showButtons('none');\n    start_timestamp = event.timeStamp;\n  }\n\n  render() {\n    return /*#__PURE__*/_jsxDEV(_Fragment, {\n      children: [this.state.speaking === true ? \"you are speaking...\" : \"Click button speak to speak\", /*#__PURE__*/_jsxDEV(\"button\", {\n        type: \"button\",\n        onClick: this.startButton,\n        children: [\" \", this.state.speaking ? Stop : Speak, \" \"]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 46,\n        columnNumber: 17\n      }, this)]\n    }, void 0, true);\n  }\n\n}\n\nexport default Speechinput;","map":{"version":3,"sources":["C:/Users/shash/Desktop/tamil_dict/e-dict/src/speechinput.js"],"names":["React","Component","SpeechRecognition","useSpeechRecognition","Speechinput","constructor","props","state","speaking","recognizing","final_transcript","recognition","webkitSpeechRecognition","componentDidMount","setState","startButton","is_listening","stop","start","ignore_onend","final_span","innerHTML","interim_span","start_img","src","showInfo","showButtons","start_timestamp","event","timeStamp","render","Stop","Speak"],"mappings":";AAAA,OAAOA,KAAP,IAAgBC,SAAhB,QAAiC,OAAjC;AACA,OAAOC,iBAAP,IAA4BC,oBAA5B,QAAwD,0BAAxD;;;;AAEA,MAAMC,WAAN,SAA0BH,SAA1B,CAAoC;AAChCI,EAAAA,WAAW,CAACC,KAAD,EAAQ;AACf,UAAMA,KAAN;AACAC,IAAAA,KAAK,GAAG;AACJC,MAAAA,QAAQ,EAAG,IADP;AAEJC,MAAAA,WAAW,EAAE,IAFT;AAGJC,MAAAA,gBAAgB,EAAE,EAHd;AAIJC,MAAAA,WAAW,EAAG,IAAIC,uBAAJ;AAJV,KAAR;AAQH;;AAEDC,EAAAA,iBAAiB,GAAG;AAChB,SAAKC,QAAL,CAAc;AAAC,kBAAW;AAAZ,KAAd;AACH;;AAEDC,EAAAA,WAAW,GAAG;AACV,UAAMC,YAAY,GAAG,KAAKT,KAAL,CAAWC,QAAhC;;AACA,QAAIQ,YAAJ,EAAkB;AACdL,MAAAA,WAAW,CAACM,IAAZ;AACA;AACD;;AACH,SAAKH,QAAL,CAAc;AAAC,0BAAmB,EAApB;AACV,0BAAmB,OADT;AAEV,gCAA0B,IAFhB;AAGV,oCAA8B;AAHpB,KAAd;AAKA,SAAKP,KAAL,CAAWI,WAAX,CAAuBO,KAAvB;AACEC,IAAAA,YAAY,GAAG,KAAf;AACAC,IAAAA,UAAU,CAACC,SAAX,GAAuB,EAAvB;AACAC,IAAAA,YAAY,CAACD,SAAb,GAAyB,EAAzB;AACAE,IAAAA,SAAS,CAACC,GAAV,GAAgB,6DAAhB;AACAC,IAAAA,QAAQ,CAAC,YAAD,CAAR;AACAC,IAAAA,WAAW,CAAC,MAAD,CAAX;AACAC,IAAAA,eAAe,GAAGC,KAAK,CAACC,SAAxB;AACL;;AAEDC,EAAAA,MAAM,GAAG;AACL,wBACI;AAAA,iBACK,KAAKvB,KAAL,CAAWC,QAAX,KAAyB,IAAzB,GAAgC,qBAAhC,GAAwD,6BAD7D,eAEI;AAAQ,QAAA,IAAI,EAAC,QAAb;AAAsB,QAAA,OAAO,EAAE,KAAKO,WAApC;AAAA,wBAAmD,KAAKR,KAAL,CAAWC,QAAX,GAAsBuB,IAAtB,GAA6BC,KAAhF;AAAA;AAAA;AAAA;AAAA;AAAA,cAFJ;AAAA,oBADJ;AAMH;;AA7C+B;;AA+CpC,eAAe5B,WAAf","sourcesContent":["import React, { Component } from 'react';\r\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\r\n\r\nclass Speechinput extends Component {\r\n    constructor(props) {\r\n        super(props);\r\n        state = {\r\n            speaking : null,\r\n            recognizing: null,\r\n            final_transcript: '',\r\n            recognition : new webkitSpeechRecognition(),\r\n\r\n        }\r\n\r\n    }\r\n\r\n    componentDidMount() {\r\n        this.setState({'speaking':false});\r\n    }\r\n\r\n    startButton() {\r\n        const is_listening = this.state.speaking;\r\n        if (is_listening) {\r\n            recognition.stop();\r\n            return;\r\n          }\r\n        this.setState({'final_transcript':'',\r\n            'recognition.lang':'ta-IN',\r\n            'recognition.continuous' :true,\r\n            'recognition.interimResults' :true\r\n        });\r\n        this.state.recognition.start();\r\n          ignore_onend = false;\r\n          final_span.innerHTML = '';\r\n          interim_span.innerHTML = '';\r\n          start_img.src = 'https://media1.giphy.com/media/LU0EPR6tWaNREI35hU/giphy.gif';\r\n          showInfo('info_allow');\r\n          showButtons('none');\r\n          start_timestamp = event.timeStamp;\r\n    }\r\n\r\n    render() {\r\n        return(\r\n            <>\r\n                {this.state.speaking ===  true ? \"you are speaking...\" : \"Click button speak to speak\"}\r\n                <button type=\"button\" onClick={this.startButton}> {this.state.speaking ? Stop : Speak} </button>\r\n            </>\r\n        )\r\n    }\r\n}\r\nexport default Speechinput;"]},"metadata":{},"sourceType":"module"}