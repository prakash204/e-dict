{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\shash\\\\Desktop\\\\tamil_dict\\\\e-dict\\\\src\\\\speechinput.js\";\nimport React, { Component } from 'react';\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nimport { Fragment as _Fragment } from \"react/jsx-dev-runtime\";\nvar recognition = new window.webkitSpeechRecognition();\nvar full_transcript = '';\n\nrecognition.onresult = function (event) {\n  var interim_transcript = '';\n\n  if (typeof event.results == 'undefined') {\n    recognition.onend = null;\n    recognition.stop();\n    upgrade();\n    return;\n  }\n\n  for (var i = event.resultIndex; i < event.results.length; ++i) {\n    if (event.results[i].isFinal) {\n      final_transcript += event.results[i][0].transcript;\n    } else {\n      interim_transcript += event.results[i][0].transcript;\n    }\n  }\n\n  final_transcript = capitalize(final_transcript);\n  final_span.innerHTML = linebreak(final_transcript);\n  interim_span.innerHTML = linebreak(interim_transcript);\n\n  if (final_transcript || interim_transcript) {\n    showButtons('inline-block');\n  }\n};\n\nclass Speechinput extends Component {\n  constructor(props) {\n    super(props);\n    this.state = {\n      speaking: null,\n      recognizing: null,\n      final_transcript: '',\n      recognition: null\n    };\n    this.startButton = this.startButton.bind(this); //this.setConfign = this.setConfign.bind(this);\n  }\n\n  async componentDidMount() {\n    await this.setState({\n      'speaking': false\n    });\n    recognition.lang = 'ta-IN';\n    recognition.continuous = true;\n    recognition.interimResults = true;\n  }\n\n  startButton() {\n    const is_listening = this.state.speaking;\n\n    if (is_listening) {\n      recognition.stop();\n      return;\n    }\n\n    recognition.start();\n  }\n\n  render() {\n    return /*#__PURE__*/_jsxDEV(_Fragment, {\n      children: [this.state.speaking === true ? \"you are speaking...\" : \"Click button speak to speak\", /*#__PURE__*/_jsxDEV(\"button\", {\n        type: \"button\",\n        onClick: this.startButton,\n        children: [\" \", this.state.speaking ? \"Stop\" : \"Speak\", \" \"]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 64,\n        columnNumber: 17\n      }, this)]\n    }, void 0, true);\n  }\n\n}\n\nexport default Speechinput;","map":{"version":3,"sources":["C:/Users/shash/Desktop/tamil_dict/e-dict/src/speechinput.js"],"names":["React","Component","SpeechRecognition","useSpeechRecognition","recognition","window","webkitSpeechRecognition","full_transcript","onresult","event","interim_transcript","results","onend","stop","upgrade","i","resultIndex","length","isFinal","final_transcript","transcript","capitalize","final_span","innerHTML","linebreak","interim_span","showButtons","Speechinput","constructor","props","state","speaking","recognizing","startButton","bind","componentDidMount","setState","lang","continuous","interimResults","is_listening","start","render"],"mappings":";AAAA,OAAOA,KAAP,IAAgBC,SAAhB,QAAiC,OAAjC;AACA,OAAOC,iBAAP,IAA4BC,oBAA5B,QAAwD,0BAAxD;;;AAEA,IAAIC,WAAW,GAAG,IAAIC,MAAM,CAACC,uBAAX,EAAlB;AACA,IAAIC,eAAe,GAAG,EAAtB;;AAEAH,WAAW,CAACI,QAAZ,GAAuB,UAASC,KAAT,EAAgB;AACnC,MAAIC,kBAAkB,GAAG,EAAzB;;AACA,MAAI,OAAOD,KAAK,CAACE,OAAb,IAAyB,WAA7B,EAA0C;AACtCP,IAAAA,WAAW,CAACQ,KAAZ,GAAoB,IAApB;AACAR,IAAAA,WAAW,CAACS,IAAZ;AACAC,IAAAA,OAAO;AACP;AACH;;AACD,OAAK,IAAIC,CAAC,GAAGN,KAAK,CAACO,WAAnB,EAAgCD,CAAC,GAAGN,KAAK,CAACE,OAAN,CAAcM,MAAlD,EAA0D,EAAEF,CAA5D,EAA+D;AAC3D,QAAIN,KAAK,CAACE,OAAN,CAAcI,CAAd,EAAiBG,OAArB,EAA8B;AAC9BC,MAAAA,gBAAgB,IAAIV,KAAK,CAACE,OAAN,CAAcI,CAAd,EAAiB,CAAjB,EAAoBK,UAAxC;AACC,KAFD,MAEO;AACPV,MAAAA,kBAAkB,IAAID,KAAK,CAACE,OAAN,CAAcI,CAAd,EAAiB,CAAjB,EAAoBK,UAA1C;AACC;AACJ;;AACDD,EAAAA,gBAAgB,GAAGE,UAAU,CAACF,gBAAD,CAA7B;AACAG,EAAAA,UAAU,CAACC,SAAX,GAAuBC,SAAS,CAACL,gBAAD,CAAhC;AACAM,EAAAA,YAAY,CAACF,SAAb,GAAyBC,SAAS,CAACd,kBAAD,CAAlC;;AACA,MAAIS,gBAAgB,IAAIT,kBAAxB,EAA4C;AACxCgB,IAAAA,WAAW,CAAC,cAAD,CAAX;AACH;AACJ,CArBD;;AAuBA,MAAMC,WAAN,SAA0B1B,SAA1B,CAAoC;AAChC2B,EAAAA,WAAW,CAACC,KAAD,EAAQ;AACf,UAAMA,KAAN;AACA,SAAKC,KAAL,GAAa;AACTC,MAAAA,QAAQ,EAAG,IADF;AAETC,MAAAA,WAAW,EAAE,IAFJ;AAGTb,MAAAA,gBAAgB,EAAE,EAHT;AAITf,MAAAA,WAAW,EAAG;AAJL,KAAb;AAOA,SAAK6B,WAAL,GAAmB,KAAKA,WAAL,CAAiBC,IAAjB,CAAsB,IAAtB,CAAnB,CATe,CAUf;AACH;;AAEsB,QAAjBC,iBAAiB,GAAG;AACtB,UAAM,KAAKC,QAAL,CAAc;AAAC,kBAAW;AAAZ,KAAd,CAAN;AACAhC,IAAAA,WAAW,CAACiC,IAAZ,GAAiB,OAAjB;AACAjC,IAAAA,WAAW,CAACkC,UAAZ,GAAwB,IAAxB;AACAlC,IAAAA,WAAW,CAACmC,cAAZ,GAA2B,IAA3B;AACH;;AAEDN,EAAAA,WAAW,GAAG;AACV,UAAMO,YAAY,GAAG,KAAKV,KAAL,CAAWC,QAAhC;;AACA,QAAIS,YAAJ,EAAkB;AACdpC,MAAAA,WAAW,CAACS,IAAZ;AACA;AACH;;AACDT,IAAAA,WAAW,CAACqC,KAAZ;AACH;;AAEDC,EAAAA,MAAM,GAAG;AACL,wBACI;AAAA,iBACK,KAAKZ,KAAL,CAAWC,QAAX,KAAyB,IAAzB,GAAgC,qBAAhC,GAAwD,6BAD7D,eAEI;AAAQ,QAAA,IAAI,EAAC,QAAb;AAAsB,QAAA,OAAO,EAAE,KAAKE,WAApC;AAAA,wBAAmD,KAAKH,KAAL,CAAWC,QAAX,GAAsB,MAAtB,GAA+B,OAAlF;AAAA;AAAA;AAAA;AAAA;AAAA,cAFJ;AAAA,oBADJ;AAMH;;AArC+B;;AAuCpC,eAAeJ,WAAf","sourcesContent":["import React, { Component } from 'react';\r\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\r\n\r\nvar recognition = new window.webkitSpeechRecognition();\r\nvar full_transcript = ''; \r\n\r\nrecognition.onresult = function(event) {\r\n    var interim_transcript = '';\r\n    if (typeof(event.results) == 'undefined') {\r\n        recognition.onend = null;\r\n        recognition.stop();\r\n        upgrade();\r\n        return;\r\n    }\r\n    for (var i = event.resultIndex; i < event.results.length; ++i) {\r\n        if (event.results[i].isFinal) {\r\n        final_transcript += event.results[i][0].transcript;\r\n        } else {\r\n        interim_transcript += event.results[i][0].transcript;\r\n        }\r\n    }\r\n    final_transcript = capitalize(final_transcript);\r\n    final_span.innerHTML = linebreak(final_transcript);\r\n    interim_span.innerHTML = linebreak(interim_transcript);\r\n    if (final_transcript || interim_transcript) {\r\n        showButtons('inline-block');\r\n    }\r\n};\r\n\r\nclass Speechinput extends Component {\r\n    constructor(props) {\r\n        super(props);\r\n        this.state = {\r\n            speaking : null,\r\n            recognizing: null,\r\n            final_transcript: '',\r\n            recognition : null\r\n\r\n        }\r\n        this.startButton = this.startButton.bind(this);\r\n        //this.setConfign = this.setConfign.bind(this);\r\n    }\r\n\r\n    async componentDidMount() {\r\n        await this.setState({'speaking':false});\r\n        recognition.lang='ta-IN';\r\n        recognition.continuous =true;\r\n        recognition.interimResults=true;\r\n    }\r\n\r\n    startButton() {\r\n        const is_listening = this.state.speaking;\r\n        if (is_listening) {\r\n            recognition.stop();\r\n            return;\r\n        }\r\n        recognition.start();\r\n    }\r\n\r\n    render() {\r\n        return(\r\n            <>\r\n                {this.state.speaking ===  true ? \"you are speaking...\" : \"Click button speak to speak\"}\r\n                <button type=\"button\" onClick={this.startButton}> {this.state.speaking ? \"Stop\" : \"Speak\"} </button>\r\n            </>\r\n        )\r\n    }\r\n}\r\nexport default Speechinput;"]},"metadata":{},"sourceType":"module"}