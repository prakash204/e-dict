{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\shash\\\\Desktop\\\\tamil_dict\\\\e-dict\\\\src\\\\speechinput.js\";\nimport React, { Component } from 'react';\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nimport { Fragment as _Fragment } from \"react/jsx-dev-runtime\";\nvar recognition = new window.webkitSpeechRecognition();\nvar full_transcript = '';\n\nclass Speechinput extends Component {\n  constructor(props) {\n    super(props);\n    this.state = {\n      speaking: null,\n      recognizing: null,\n      final_transcript: '',\n      recognition: null\n    };\n    this.startButton = this.startButton.bind(this); //this.setConfign = this.setConfign.bind(this);\n  }\n\n  async componentDidMount() {\n    await this.setState({\n      'speaking': false\n    });\n    recognition.lang = 'ta-IN';\n    recognition.continuous = true;\n    recognition.interimResults = true;\n  }\n\n  startButton() {\n    const is_listening = this.state.speaking;\n\n    if (is_listening) {\n      recognition.stop();\n      return;\n    }\n\n    recognition.start();\n  }\n\n  render() {\n    return /*#__PURE__*/_jsxDEV(_Fragment, {\n      children: [this.state.speaking === true ? \"you are speaking...\" : \"Click button speak to speak\", /*#__PURE__*/_jsxDEV(\"button\", {\n        type: \"button\",\n        onClick: this.startButton,\n        children: [\" \", this.state.speaking ? \"Stop\" : \"Speak\", \" \"]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 41,\n        columnNumber: 17\n      }, this)]\n    }, void 0, true);\n  }\n\n}\n\nexport default Speechinput;","map":{"version":3,"sources":["C:/Users/shash/Desktop/tamil_dict/e-dict/src/speechinput.js"],"names":["React","Component","SpeechRecognition","useSpeechRecognition","recognition","window","webkitSpeechRecognition","full_transcript","Speechinput","constructor","props","state","speaking","recognizing","final_transcript","startButton","bind","componentDidMount","setState","lang","continuous","interimResults","is_listening","stop","start","render"],"mappings":";AAAA,OAAOA,KAAP,IAAgBC,SAAhB,QAAiC,OAAjC;AACA,OAAOC,iBAAP,IAA4BC,oBAA5B,QAAwD,0BAAxD;;;AAEA,IAAIC,WAAW,GAAG,IAAIC,MAAM,CAACC,uBAAX,EAAlB;AACA,IAAIC,eAAe,GAAG,EAAtB;;AAEA,MAAMC,WAAN,SAA0BP,SAA1B,CAAoC;AAChCQ,EAAAA,WAAW,CAACC,KAAD,EAAQ;AACf,UAAMA,KAAN;AACA,SAAKC,KAAL,GAAa;AACTC,MAAAA,QAAQ,EAAG,IADF;AAETC,MAAAA,WAAW,EAAE,IAFJ;AAGTC,MAAAA,gBAAgB,EAAE,EAHT;AAITV,MAAAA,WAAW,EAAG;AAJL,KAAb;AAOA,SAAKW,WAAL,GAAmB,KAAKA,WAAL,CAAiBC,IAAjB,CAAsB,IAAtB,CAAnB,CATe,CAUf;AACH;;AAEsB,QAAjBC,iBAAiB,GAAG;AACtB,UAAM,KAAKC,QAAL,CAAc;AAAC,kBAAW;AAAZ,KAAd,CAAN;AACAd,IAAAA,WAAW,CAACe,IAAZ,GAAiB,OAAjB;AACAf,IAAAA,WAAW,CAACgB,UAAZ,GAAwB,IAAxB;AACAhB,IAAAA,WAAW,CAACiB,cAAZ,GAA2B,IAA3B;AACH;;AAEDN,EAAAA,WAAW,GAAG;AACV,UAAMO,YAAY,GAAG,KAAKX,KAAL,CAAWC,QAAhC;;AACA,QAAIU,YAAJ,EAAkB;AACdlB,MAAAA,WAAW,CAACmB,IAAZ;AACA;AACH;;AACDnB,IAAAA,WAAW,CAACoB,KAAZ;AACH;;AAEDC,EAAAA,MAAM,GAAG;AACL,wBACI;AAAA,iBACK,KAAKd,KAAL,CAAWC,QAAX,KAAyB,IAAzB,GAAgC,qBAAhC,GAAwD,6BAD7D,eAEI;AAAQ,QAAA,IAAI,EAAC,QAAb;AAAsB,QAAA,OAAO,EAAE,KAAKG,WAApC;AAAA,wBAAmD,KAAKJ,KAAL,CAAWC,QAAX,GAAsB,MAAtB,GAA+B,OAAlF;AAAA;AAAA;AAAA;AAAA;AAAA,cAFJ;AAAA,oBADJ;AAMH;;AArC+B;;AAuCpC,eAAeJ,WAAf","sourcesContent":["import React, { Component } from 'react';\r\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\r\n\r\nvar recognition = new window.webkitSpeechRecognition();\r\nvar full_transcript = ''; \r\n\r\nclass Speechinput extends Component {\r\n    constructor(props) {\r\n        super(props);\r\n        this.state = {\r\n            speaking : null,\r\n            recognizing: null,\r\n            final_transcript: '',\r\n            recognition : null\r\n\r\n        }\r\n        this.startButton = this.startButton.bind(this);\r\n        //this.setConfign = this.setConfign.bind(this);\r\n    }\r\n\r\n    async componentDidMount() {\r\n        await this.setState({'speaking':false});\r\n        recognition.lang='ta-IN';\r\n        recognition.continuous =true;\r\n        recognition.interimResults=true;\r\n    }\r\n\r\n    startButton() {\r\n        const is_listening = this.state.speaking;\r\n        if (is_listening) {\r\n            recognition.stop();\r\n            return;\r\n        }\r\n        recognition.start();\r\n    }\r\n\r\n    render() {\r\n        return(\r\n            <>\r\n                {this.state.speaking ===  true ? \"you are speaking...\" : \"Click button speak to speak\"}\r\n                <button type=\"button\" onClick={this.startButton}> {this.state.speaking ? \"Stop\" : \"Speak\"} </button>\r\n            </>\r\n        )\r\n    }\r\n}\r\nexport default Speechinput;"]},"metadata":{},"sourceType":"module"}